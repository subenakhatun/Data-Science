{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ad01bdf",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "## TF কাকে বলে?\n",
    "#### TF(Term frequency): মানে কোন শব্দ তোমার বাক্যে কতবার এসেছে বা আছে সেটা একটা সংখ্যায় প্রকাশ করা যেন মেশিন এটা বিশ্লেষণ করতে পারে। \n",
    "একটা শব্দ একটা ডকুমেন্ট বা একটা বাক্যে কয়বার আছে। <br>\n",
    "যেমনঃ I am Bangladeshi and i love Bangladesh.<br>\n",
    "এই বাক্যে:<br>\n",
    "I --> 2 বার আছে<br>\n",
    "am ---> ১ বার আছে<br>\n",
    "Bnagladesh ---> ১ বার আছে<br>\n",
    "and ---> ১ বার আছে<br>\n",
    "love ---> ১ বার আছে<br>\n",
    "Bangladeshi ---> ১ বার আছে<br>\n",
    "\n",
    "### TF এর ফর্মুলাঃ \n",
    "TF(word) = (একটা শব্দ কতবার আছে বা এসেছে / মোট শব্দ সংখ্যা) <br>\n",
    "TF('I') = 2/7 = 0.285 <br>\n",
    "TF('love') = 1/7 = 0.142 <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d41ebe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Frequencies (TF):\n",
      "\n",
      "i: 0.286\n",
      "am: 0.143\n",
      "bangladeshi: 0.143\n",
      "and: 0.143\n",
      "love: 0.143\n",
      "bangladesh: 0.143\n"
     ]
    }
   ],
   "source": [
    "# Term Frequency\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Sample sentence\n",
    "text = \"I am Bangladeshi and i love Bangladesh.\"\n",
    "\n",
    "# Step 2: Preprocess - lowercase and tokenize\n",
    "words = text.lower().replace(\".\", \"\").split()\n",
    "\n",
    "# Step 3: Count word frequencies\n",
    "word_counts = Counter(words)\n",
    "total_words = len(words)\n",
    "\n",
    "# Step 4: Calculate TF for each word\n",
    "tf_scores = {word: round(count / total_words, 3) for word, count in word_counts.items()}\n",
    "print(\"Term Frequencies (TF):\\n\")\n",
    "for word, tf in tf_scores.items():\n",
    "    print(f\"{word}: {tf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeed86d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ed4b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'I am Bangladeshi and i love Bangladesh.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac1c2167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make objects\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8478f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit transform\n",
    "tf_fit = tfidf.fit_transform([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b6a19bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'love': 2, 'myself': 4, 'and': 0, 'my': 3, 'dream': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check every vocabulary or word in endcoding \n",
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c4b6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92e40a42",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
